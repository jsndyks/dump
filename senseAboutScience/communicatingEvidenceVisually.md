<link rel="stylesheet" href="https://jsndyks.github.io/sg2047/css/sg2047.css">

# Communicating Evidence Visually : NOTES

Hi - that was an interesting discussion, thanks for the invite.

I liked the objective - a useful thing to work towards: that graphics should be “_transparent to a motivated citizen_”.
But do we know what skills and competencies they are expected to have?

I think designing graphics is a bit like developing policy - you need to have access to the science, understand it, and be able to interpret and apply it as you use your skills in visualization design to present a data set in ways that make sense, and perhaps support a particular argument.
You also need to be able to justify your choices in light of this knowledge, your audience and your intent.
See what I mean?

For this to work you need :

- education - visual literacy in the audience and the design team
- rationale - explicit discourse around design decisions, rationale and what you gain / lose through each.

That’s the _pathway to openness_ in my view and graphics provide a nuanced and detailed language through which this might be achieved.

There is also something else to be said. To understand science, or even The World, you need to be able to interpret distributions, rather than single numbers. That’s how the World is - uncertain, but predictable within ranges. Probability and distributions are key to this. Politicians need to be able to make decisions and develop policy with an understanding of distributions and probabilities. It’s a bit weird that so many of them seem to have backgrounds in arts subjects and study PPE at Oxford, but there you go. It would be great to get them working with measures of central tendency and dispersion to describe distributions. The good news is that visualization gives us great scope for doing this very effectively.
There is hope!

But visual data design is a complex science and society driven craft.
What we really need are (data) designers who understand the science and the message and the craft of data design!
This requires training and funding!
Of course we run courses that try to develop these, and we’re always looking for opportunities to engage to develop and run more!

OK - on to yesterday’s questions and discussion …

## What do we Know?

VIS research involves enabling technology and algorithms, human experiments that help us understand likely responses to graphics, design work that develops viable approaches in particular applied contexts and reports upon what is learned, and engineering in which systems and workflows are designed and developed that draw upon all of this to make sense of data in particular contexts, and give tools and capabilities to others so that they can do the same.
We try to develop guidelines and theory through all of this.
It is best captured and indeed supported by the annual conference [IEEE VIS](https://ieeevis.org/) and associated journal _IEEE Transactions in Visualization and Computer Graphics_.
You can see some of what we have done on our painfully outdated Web pages: [https://www.gicentre.net/featuredpapers/](https://www.gicentre.net/featuredpapers/)

To answer the specific questions that were listed on the agenda, from a _VIS research_ (_"evidence based"_) perspective …

### PHYSICALLY

I think we know quite a lot about what goes on in people’s heads when they look at simple graphics.
**Steve Franconeri** and some other cognitive scientists tried to summarise some of this here and suggest some actions as a result.

> Franconeri, Steven L., et al. "The science of visual data communication: What works." Psychological Science in the public interest 22.3 (2021): 110-161.

**Danielle Szafir** also runs a good group, who do good work and attempt to show how Vision Science can help us do good vis. Their design space helps explain this.

> Elliott, M. A., Nothelfer, C., Xiong, C., & Szafir, D. A. (2020). A design space of vision science methods for visualization research. IEEE Transactions on Visualization and Computer Graphics, 27(2), 1117-1127.
> [https://youtu.be/v6bJwsHxRLY](https://youtu.be/v6bJwsHxRLY)

### EMOTIONALLY

There are various studies on affect and visualization - these are good starting points.

> Pandey, A. V., Manivannan, A., Nov, O., Satterthwaite, M., & Bertini, E. (2014). The persuasive power of data visualization. IEEE transactions on visualization and computer graphics, 20(12), 2211-2220.

I like the affective learning objectives approach, which gets us to be explicit about how we are trying to make people feel. \__Elsie Lee-Robins_’\_ paper captures this nicely.

> Lee-Robbins, E., & Adar, E. (2022). Affective Learning Objectives for Communicative Visualizations. IEEE Transactions on Visualization and Computer Graphics, 29(1), 1-11.

Most VIS papers have an accompanying presentation video - useful!<br/>
[https://youtu.be/2MJlzAd9Ua0](https://youtu.be/2MJlzAd9Ua0)

Or see it live!<br/>
[https://youtu.be/Hcx-DoHkWuk?t=1178](https://youtu.be/Hcx-DoHkWuk?t=1178)

Or, _if you only have 30 seconds_, try the teaser trailer!<br/>
[https://youtu.be/UrW92ubvSdo](https://youtu.be/UrW92ubvSdo)

### COMPREHENSION & MISUNDERSTANDING

You cannot guarantee that graphics will not be used to misinform or that they will not be misinterpreted, as is the case with text - which can be used for misinformation and in some cases will do more harm than good.
_How to Lie with Maps_ - \__Dennis Wood_’s\_ classic book - reminds us that bias and propaganda are well known phenomena in cartography. There are loads of research papers on this, but the most important message is that it’s complicated and unpredictable!

See here for an example that attempts to study, explain and quantify some of this:

> Xiong, C., Stokes, C., Kim, Y. S., & Franconeri, S. (2022). Seeing what you believe or believing what you see? belief biases correlation estimation. IEEE Transactions on Visualization and Computer Graphics, 29(1), 493-503.<br/> > [https://youtu.be/7ISD9WtYChI](https://youtu.be/7ISD9WtYChI) - worth 30 seconds!<br/> > [https://youtu.be/xBSZC2jj_wc](https://youtu.be/xBSZC2jj_wc) - 12 min paper

### OTHER EFFECTS

There are numerous other effects that are known and understood with different levels of clarity:

- Anchoring
- Priming
- Framing
- Context
- Uncertainty
- Memorability, Recognition, Recall - _different objectives_
- Multimodal, Physical, Accessible - _where do different modalities and accessibility fit in_?
- Interaction - _very effective, but makes everything more complex_
- Technology - _many things change as tech progresses_

There is a nice framework here :

> Dimara, E., Franconeri, S., Plaisant, C., Bezerianos, A., & Dragicevic, P. (2018). A task-based taxonomy of cognitive biases for information visualization. IEEE Transactions on Visualization and Computer Graphics, 26(2), 1413-1432.<br/> > [https://vimeo.com/373008296](https://vimeo.com/373008296)<br/> > [https://vimeo.com/364568413](https://vimeo.com/364568413)

Some places to look include:

> Valdez, A. C., Ziefle, M., & Sedlmair, M. (2017). Priming and anchoring effects in visualization. IEEE Transactions on Visualization and Computer Graphics, 24(1), 584-594.

> Borkin, M. A., Bylinskii, Z., Kim, N. W., Bainbridge, C. M., Yeh, C. S., Borkin, D., ... & Oliva, A. (2015). Beyond memorability: Visualization recognition and recall. IEEE Transactions on Visualization and Computer Graphics 22(1), 519-528.

> Mukherjee, K., Yin, B., Sherman, B. E., Lessard, L., & Schloss, K. B. (2021). Context matters: A theory of semantic discriminability for perceptual encoding systems. IEEE Transactions on Visualization and Computer Graphics, 28(1), 697-706.

### VISUALIZING UNCERTAINTY

I would definitely look at \__Jessica Hullman_’s\_ excellent work on uncertainty, she is running a group that is galloping towards evidence-based guidelines and approaches that should be useful to policymakers and government.For example, see …

> Hullman, J., & Diakopoulos, N. (2011). Visualization rhetoric: Framing effects in narrative visualization. IEEE Transactions on Visualization and Computer Graphics, 17(12), 2231-2240.

> Hullman, J., Drucker, S., Riche, N. H., Lee, B., Fisher, D., & Adar, E. (2013). A deeper understanding of sequence in narrative visualization. IEEE Transactions on Visualization and Computer Graphics, 19(12), 2406-2415.

> Kay, M., Kola, T., Hullman, J. R., & Munson, S. A. (2016, May). When (ish) is my bus? User-centered visualizations of uncertainty in everyday, mobile predictive systems. In Proceedings of the 2016 chi conference on human factors in computing systems (pp. 5092-5103).

Many papers have 30 second video summaries … again - useful!<br/>
[https://youtu.be/jr50GY5RYI8](https://youtu.be/jr50GY5RYI8)

### OTHER OTHER EFFECTS 😉

**Cindy Xiong** (along with some of the above) is doing some great work on ‘other effects’ - for example:

> Burns, A., Xiong, C., Franconeri, S., Cairo, A., & Mahyar, N. (2020, October). How to evaluate data visualizations across different levels of understanding. In 2020 IEEE Workshop on Evaluation and Beyond-Methodological Approaches to Visualization (BELIV) (pp. 19-28). IEEE.

> Xiong, C., Shapiro, J., Hullman, J., & Franconeri, S. (2019). Illusion of causality in visualized data. IEEE Transactions on Visualization and Computer Graphics, 26(1), 853-862.
> Try the 30 second preview to know why PopTarts are important!<br/> > [https://vimeo.com/360049821](https://vimeo.com/360049821)
> Or the 12 minute talk for more depth:<br/> > [https://vimeo.com/370881473](https://vimeo.com/370881473)

### VARIOUS

Some other ideas came to mind during the meeting ... so I jotted down some additional notes ...

**Concrete scales** are interesting and were suggested yesterday (balloons) - they seem to have potential:

> Chevalier, F., Vuillemot, R., & Gali, G. (2013). Using concrete scales: A practical framework for effective visual depiction of complex measures.  IEEE Transactions on Visualization and Computer Graphics, 19(12), 2426-2435.

There is a fair amount of work on visualization of **Bayesian** stats and reasoning. **Lane Harrison** is good:

> Ottley, A., Peck, E. M., Harrison, L. T., Afergan, D., Ziemkiewicz, C., Taylor, H. A., ... & Chang, R. (2015). Improving Bayesian reasoning: The effects of phrasing, visualization, and spatial ability.  IEEE Transactions on Visualization and Computer Graphics, 22(1), 529-538.

We also discussed **“Text or Words”** and **Prof.\_ \_Marti Hearst**, Head of School of Information at Berkeley, had plenty of useful things to say at IEEEVIS in 2022.
Her _“Show it or Tell it?_” keynote on words and graphics is an hour long bu provides an excellent overview.<br/>
[https://www.youtube.com/watch?v=BDTEkT8p4Gs](https://www.youtube.com/watch?v=BDTEkT8p4Gs)

**Positioning yourself** in the data was discussed - See _PersaLog_ for some great ideas!

> Adar, E., Gearig, C., Balasubramanian, A., & Hullman, J. (2017, May). PersaLog: Personalization of news article content. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 3188-3200).<br/> > [https://youtu.be/zVi6zy1LLjo](https://youtu.be/zVi6zy1LLjo)

**Data Comics** were mentioned - **Ben Bach** at Edinburgh is the person to connect with here:

> Bach, B., Riche, N. H., Carpendale, S., & Pfister, H. (2017). The emerging genre of data comics. IEEE computer graphics and applications, 37(3), 6-13.

> Bach, B., Wang, Z., Farinella, M., Murray-Rust, D., & Henry Riche, N. (2018, April). Design patterns for data comics. In Proceedings of the 2018 CHI conference on human factors in computing systems (pp. 1-12).

I strongly would recommend connecting with the **Edinburgh** group - they are great.
The _VisHub at Edinburgh_ is exciting - good researchers and good connections between art, science, design and Vis.<br/>
[https://vishub.net/](https://vishub.net/)
They are also hosting the _Information+_ conference this year - and you should get along!<br/>
[https://informationplusconference.com/2023/](https://informationplusconference.com/2023/)

**Accessibility** - I have just returned from a week at the _Schloss Dagstuhl – Leibniz Center for Informatics_, discussing _Inclusive Data Visualization_ with colleagues from around the World. Some of them were blind and partially sighted. It’s a conundrum. Using multiple media is strongly recommended and the DAISY Consortium provides some tools to help with specifications and transformation. [https://daisy.org/](https://daisy.org/)

**Design Process** - this was discussed briefly right at the end!
I’d vouch for testing, iteration and co-design as mentioned right at the end. And the VIS community has tested design methodologies to help with this! For example, using visual stimuli for creative problem solving as we specify need and design tools to address it in light of data.

**Connecting with the VIS Research Community**
Note that any of these people would welcome questions that they can work on!
They are up for discussion and can help formulate answerable questions and answer them.

### GUIDELINES

For design guidelines, I really quite like the elegance of the rules in **Kindlmann & Scheidegger’s** Algebraic Visualization.

It’s not super-accessible, but the concepts are really useful once you get them - good checks!
e.g. Changing the encoding (visualization) should not change the interpretation (you can think of this as visualization reliability).

> Kindlmann, G., & Scheidegger, C. (2014). An algebraic process for visualization design. IEEE transactions on visualization and computer graphics, 20(12), 2181-2190.

Perhaps more accessible and useful are the science informed sites and blogs … there are loads of these:
great sites and resources that take the science and explain it well - with functionality to make it accessible.

See **ColorBrewer** - empirically derived colour schemes for numeric sequences, orders and discriminable categories.<br/>
[https://colorbrewer2.org/](https://colorbrewer2.org/)

**Lisa Charlotte Muth** at _DataWrapper_ produces some fantastic guides - on colour and other aspects of visualization design.<br/>
[https://lisacharlottemuth.com/articles](https://lisacharlottemuth.com/articles)

**Kennedy Elliott** - now at the _NY Times_ - did a great interpretation of 39 studies in Human Perception that inform visualization design<br/>
[https://medium.com/@kennelliott/39-studies-about-human-perception-in-30-minutes-4728f9e31a73](https://medium.com/@kennelliott/39-studies-about-human-perception-in-30-minutes-4728f9e31a73)

### BOOKS

There are great books that explain and help and provide inspiration.

_Dear Data_ - just get this and cherish it. Giorgia Lupi and Steph Posavec opened up all kinds of opportunities here and their Data Humanism presents aposition that is important in terms of engagement and some of the issues around trustm fairness and infantilization that were mentioned yesterday.

> Lupi, G., & Posavec, S. (2016). Dear data. Chronicle books.<br/> > [http://www.dear-data.com/](http://www.dear-data.com/)

I like **Isabel Meirelles** book - _Design for Information_ - as it makes direct reference to some of the science and positions data visualization as part of a long-standing tradition of visual communication (which it is).<br/>

> Meirelles, I. (2013). Design for information: an introduction to the histories, theories, and best practices behind effective information visualizations. Rockport publishers.<br/> > [https://isabelmeirelles.com/about/](https://isabelmeirelles.com/about/)<br/> > [https://www.amazon.com/gp/product/1592538061/](https://www.amazon.com/gp/product/1592538061/)

**Johnathan Schwabish’s** _Better Data Visualizations_ is a bit hit and miss, but he is very much involved with policy at _PolicyViz_ so I think this would be a good thing to have a look at too.<br/>

> Schwabish, J. (2021). Better data visualizations: A guide for scholars, researchers, and wonks. Columbia University Press.<br/> > [https://www.amazon.com/gp/product/1592538061/](https://www.amazon.com/gp/product/1592538061/)<br/> > [https://policyviz.com/](https://policyviz.com/)

There was an assumption about using paper and screens yesterday, but _Data Physicalization_ is expressive and engaging and big news. There is a new and exciting book on this :

> Huron, S., Nagel, T., Oehlberg, L., & Willett, W. (2021). Making with Data.<br/> > [http://makingwithdata.org/](http://makingwithdata.org/)<br/> > [https://www.amazon.com/Making-Data-Physical-Data-Driven-Visualization/dp/1032182229/](https://www.amazon.com/Making-Data-Physical-Data-Driven-Visualization/dp/1032182229/)

### EVIDENCE

Finally … (at last) …

I would say that arguments are the most important thing in all of this.
Make them, expose them, communicate them, have them tested, use vis well. That’s ‘open’. No policy is anything other than the interpretation of evidence to develop action that is intended to achieve a particular aim. None is perfect, none is objective. There are always alternatives and choices and these require explanation and justification. That’s where _“follows the science”_ was wrong. The science is not _"followable"_. I think it’s more accurate and useful to say that policy is _“fully informed by science”_ or even _"adequately informed by relevant science"_ and then explain how - what was used, what was ignored? And even what was deemed _adequate_ and _relevant_ and why.
Vis gives us language for this.

Somewhere you asked …

- _“Does it [visualization] help or hinder communication”_?

Well, there is scope for both.
But it does make policy and decision-making more open.
(If your designs are adequate)

You can’t have your cake and eat it - more open, means more open to question, more scrutinised, and I think we should welcome that.
Being more open exposes you to more scrutiny and if your arguments don’t hold up, your narrative is challenged, you’ll be called out.
That has to be good for society and for democracy!

So I hope we can use vis design and research to help.

---

**Jason DYKES**
28/06/23
